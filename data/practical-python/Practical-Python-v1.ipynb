{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>Cockroach Developer Success - \n",
    "    Practial Python</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this Notebook we will connect to your CC Free Tier cluster and perform some basic operations in Python\n",
    "<p>Firstly you will need to log in using an admin user to create the required database and user:</p><br>\n",
    "<code>cockroach sql --url \"postgresql://USER:PASSWORD@ADDRESS:26257/CLUSTER_NAME.defaultdb?sslmode=require\"\n",
    "> create database tp2019;\n",
    "> create user tp2019_user with password th0rp3park;\n",
    "> grant all on database tp2019 to tp2019_user;\n",
    "</code>\n",
    "<p>Next, let's import a few libraries that we need to use.\n",
    "<p>You will need to make sure that you have installed the the following libraries using pip:</p>\n",
    "<code>pip install psycopg2.binary sqlalchemy sqlalchemy-cockroachdb pandas matplotlib openpyxl</code>\n",
    "<p>Here is the link to the <a href=\"https://www.cockroachlabs.com/docs/stable/build-a-python-app-with-cockroachdb-sqlalchemy.html\">CockroachDB docs page for Python</a> if you get stuck or need more information</p><br>\n",
    "<p>OK, let's get started with the Python. We need to import some libraries the most important of which is psycopg2 - the most common PostgreSQL driver for Python ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pprint as pp\n",
    "import csv\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now let's set up some connection strings\n",
    "<p><b>Important:</b> you will need to enter the address and cluster name of your CC Free Tier cluster in the cell below</p>\n",
    "<p>Note how the details in the URL map to the component parts of the connect string. You can use either version with psycopg2, some PostgreSQL-compatible tools will need the component parts to be specified individually while others like SQLAlchemy will only accept the URL version (with a small tweak).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_address = 'xxxxxxxxx.cockroachlabs.cloud'\n",
    "cc_cluster_name = 'xxxxxxxxx'\n",
    "\n",
    "my_cc_free_tier_url = 'postgresql://tp2019_user:th0rp3park@{}:26257/{}.tp2019?sslmode=require'.format(cc_address,cc_cluster_name)\n",
    "my_cc_free_tier_parts = \"host='{}' port=26257 dbname='{}.tp2019' user='tp2019_user' password='th0rp3park' sslmode='require'\".format(cc_address,cc_cluster_name)\n",
    "\n",
    "print('URL:', my_cc_free_tier_url)\n",
    "print('Parts:', my_cc_free_tier_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also set up some functions to make things easier for us later on ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pg_connect(conn_str):\n",
    "\n",
    "        conn = psycopg2.connect(conn_str)    \n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"SET application_name = 'Jupyter notebook'\")\n",
    "        cur.close()\n",
    "        \n",
    "        return conn\n",
    "\n",
    "def pg_fetch_one(conn, query_str):\n",
    "    \n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query_str)\n",
    "        result = cursor.fetchone()\n",
    "        cursor.close();\n",
    "\n",
    "        return result\n",
    "\n",
    "def pg_fetch_all(conn, query_str):\n",
    "    \n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query_str)\n",
    "        result = cursor.fetchall()\n",
    "        cursor.close();\n",
    "\n",
    "        return result\n",
    "\n",
    "def pg_execute(conn, sql_str):\n",
    "    \n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql_str)\n",
    "        cursor.close();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Connect to the cluster</h2>\n",
    "<p>Here we use the pg_connect() function we defined above and pass it the connection string as an argument.\n",
    "<p>This function runs a statement against the cluster to set the application name. This can be very useful when trying to work out which applications are connected to the cluster. In your <code>cockroach sql</code> shell you can issue the following command to see which applications are connected:</p><br>\n",
    "<code>> show sessions;\n",
    "</code>\n",
    "<p>Run this before and after executing the following cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_conn = pg_connect(my_cc_free_tier_url)\n",
    "pg_conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Note that in Python when you specify a variable on its own you get the value it contains - in this case you can see that <code>pg_conn</code> is a connection object, the connection string or URL that was used to open the connection (with password obscured) and that it is currently open (indicated by closed: 0)</p>\n",
    "<p>Let's create a table in the tp2019 database using the pg_execute() function that we defined above.</p>\n",
    "<p>This table is designed to store the results from the Thorpe Park Triathlon held in September 2019. Thorpe Park is a theme park close to London and is also the venue for this multi-sport event twice a year. If you take part in the triathlon you can have access to the park and it's rides for free afterwards (if you're not too tired that is).</p>\n",
    "<p>For those of you who are not familiar with triathlon, it is a multi-discipline continuous event combining swimming, cycling and running. Although there are 3 main diciplines, we also have 2 transitions between the main diciplines. This means that the clock is ticking the whole time and the triathlon is actually composed of 5 distinct phases:</p>\n",
    "<ul><li>The swim - 1500m (just under a mile)<li>The transition between the swim and the cycle (T1)<li>The cycle - 20km (about 13 miles)<li>The transition between the cycle and the run (T2)<li>The run - 5k (a shade over 3 miles)</ul>\n",
    "<p>Although we refer to the length of each segment as a time, it is actually an interval (the difference between 2 times) and we have a datatype INTERVAL in CockroachDB which is ideal for storing this kind of data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table_ddl = \"\"\"\n",
    "CREATE TABLE results (\n",
    "  position integer, \n",
    "  race_no integer primary key,\n",
    "  full_name varchar(50),\n",
    "  total_time INTERVAL,\n",
    "  category char(5),\n",
    "  cat_position integer,\n",
    "  gender varchar(6),\n",
    "  gen_position integer,\n",
    "  club_name varchar(50),\n",
    "  swim_time INTERVAL,\n",
    "  t1_time INTERVAL,\n",
    "  cycle_time INTERVAL,\n",
    "  t2_time INTERVAL,\n",
    "  run_time INTERVAL\n",
    ")\n",
    "\"\"\"\n",
    "pg_execute(pg_conn, results_table_ddl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Note that you can specify datatypes as PostgreSQL types, native CockroachDB types or a mixture of the two.</p>\n",
    "<p>If you execute the following in the sql shell you will see that the results table has been created:</p>\n",
    "<code>> \\d tp2019.results</code>\n",
    "<pre>\n",
    "  column_name  |  data_type  | is_nullable | column_default | generation_expression |  indices  | is_hidden\n",
    "---------------+-------------+-------------+----------------+-----------------------+-----------+------------\n",
    "  position     | INT8        |    true     | NULL           |                       | {}        |   false\n",
    "  race_no      | INT8        |    false    | NULL           |                       | {primary} |   false\n",
    "  full_name    | VARCHAR(50) |    true     | NULL           |                       | {}        |   false\n",
    "  total_time   | INTERVAL    |    true     | NULL           |                       | {}        |   false\n",
    "  category     | CHAR(5)     |    true     | NULL           |                       | {}        |   false\n",
    "  cat_position | INT8        |    true     | NULL           |                       | {}        |   false\n",
    "  gender       | VARCHAR(6)  |    true     | NULL           |                       | {}        |   false\n",
    "  gen_position | INT8        |    true     | NULL           |                       | {}        |   false\n",
    "  club_name    | VARCHAR(50) |    true     | NULL           |                       | {}        |   false\n",
    "  swim_time    | INTERVAL    |    true     | NULL           |                       | {}        |   false\n",
    "  t1_time      | INTERVAL    |    true     | NULL           |                       | {}        |   false\n",
    "  cycle_time   | INTERVAL    |    true     | NULL           |                       | {}        |   false\n",
    "  t2_time      | INTERVAL    |    true     | NULL           |                       | {}        |   false\n",
    "  run_time     | INTERVAL    |    true     | NULL           |                       | {}        |   false\n",
    "(14 rows)\n",
    "</pre>\n",
    "<p>Note that some PostgreSQL types will be converted to CockroachDB equivalents - for example <b>integer</b> has been converted to <b>INT8</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading data</h2>\n",
    "<p>Now let's populate the table with data from a csv file downloaded from the event website.</p>\n",
    "<p>Firstly let's try the copy_from() method for a psycopg2 cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works with PostgreSQL, but the COPY function is not implemented in CockroachDB\n",
    "cur = pg_conn.cursor()\n",
    "f = open('TP2019.csv', 'r')\n",
    "cur.copy_from(f, 'results', sep=',')\n",
    "f.close()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>OK, so that didn't work - although the PostgreSQL COPY command <b>is</b> implemented in CockroachDB, it appears that we have not replicated every combination of the syntax exactly - see the <a href=\"https://www.cockroachlabs.com/docs/v21.1/copy-from.html\">COPY FROM docs page</a>. \n",
    "<p>CockroachDB implements the ProstgreSQL wire protocol and a large proportion of the PostgreSQL syntax, but it is not a fork of Postgres - it is written from scratch and not every PostgreSQL feature is implemented or fully replicated.\n",
    "<p>Let's try another method. \n",
    "<ol>\n",
    "    <li>Open the csv file for reading\n",
    "    <li>Loop though the lines in the file and construct/execute a number of INSERT statements\n",
    "    <li>Commit periodically to make sure our changes are saved and we don't overload a single transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_cur = pg_conn.cursor()\n",
    "with open('TP2019.csv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    rows_max = 25;\n",
    "    rows = 0;\n",
    "    insert_str = \"INSERT INTO results VALUES \"\n",
    "    for record in reader:\n",
    "        rows += 1\n",
    "        insert_str += \"({}, {}, '{}', '{}', '{}', {}, '{}', {}, '{}','{}','{}','{}','{}','{}')\".format(\n",
    "            record[0],record[1],record[2],record[3],record[4],record[5],record[6],\n",
    "                   record[7],record[8],record[9],record[10],record[11],record[12],record[13])        \n",
    "        if (rows == rows_max):\n",
    "            insert_str = insert_str.replace(\",,\",\",null,\") + \";\"\n",
    "            #print(insert_str)\n",
    "            pg_cur.execute(insert_str)\n",
    "            pg_conn.commit()\n",
    "            rows = 0;\n",
    "            insert_str = \"INSERT INTO results VALUES \"\n",
    "        else:\n",
    "            insert_str += ','\n",
    "    insert_str = insert_str.replace(\",,\",\",null,\").rstrip(\",\") + \";\"\n",
    "    print(insert_str)\n",
    "    pg_cur.execute(insert_str)\n",
    "pg_conn.commit()\n",
    "pg_cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The INSERT statement printed out above is just the last one executed for illustration purposes. Rows are inserted in batches of 25 - the last statement has the final 8 rows generated after loading (and committing) 10 batches of 25 rows.</p>\n",
    "<p>You can confirm that all the data has been loaded in the CLI using <code>select count(*) from results</code> - there should be 258 rows.</p>\n",
    "<p>It would have been much simpler to contruct an INSERT statement for each row in the csv file, but the problem with this approach is that each time you execute a SQL statement there is a round trip to the Cockroach cluster. So if you are based in Europe and your cluster is located in central USA there will be around 100ms round trip delay for each interaction. This load would have taken around 25 seconds which is just about bearable but what if you have 10,000 rows to upload (or more)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Selecting and manipulating data</h2>\n",
    "<p>Now let's perform some queries against our uploaded data - this one brings back a single row - who is this chap and how on earth did he get out of a wetsuit and onto the bike course in 73 seconds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_result = pg_fetch_one(pg_conn, \"SELECT * FROM results WHERE race_no = 473\")\n",
    "pp.pprint(my_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now let's bring back the top 10 and limit the columns returned to position, name and total_time. We'll also process the results with a simple Python for loop ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_query_str = \"\"\"\n",
    "SELECT position,full_name,total_time \n",
    "FROM results\n",
    "ORDER BY position\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "top10 = pg_fetch_all(pg_conn, top_10_query_str)\n",
    "for row in top10:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can also modify the contents of one or more rows with UPDATE. \n",
    "<p>Let's bump a certain Cockroach Labs employee into the top spot by swapping him with the person in first place ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheating_update_str = \"\"\"\n",
    "UPDATE results SET position=1, total_time='00:59:59' WHERE race_no = 473;\n",
    "UPDATE results SET position=124, total_time=5055::INTERVAL WHERE race_no = 369;\n",
    "\"\"\" \n",
    "pg_execute(pg_conn, cheating_update_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Note that we can execute more than one statement by separating with a semi-colon - this will prevent multiple round trips to the Cockroach cluster\n",
    "<p>Now go back to the previous query above and re-run the cell to see effect of the changes. You will should see that we have a new winner - and the time was just under an hour!!\n",
    "<p><code>(1, 'Alistair Parry', datetime.timedelta(seconds=3599))</code>\n",
    "<p>By default each statement is executed in its own (implicit) transaction which means that it is possible that one of the UPDATEs succeeds and the other fails. In this case we could potentially end up with 2 athletes in the same position!\n",
    "\n",
    "We can confirm the situation by checking the value of the autocommit attribute of our connection ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (pg_conn.autocommit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To make sure that both statements succeed or both fail (maintaining the integrity of the data) we can execute the statements inside an explit transaction. \n",
    "<p>We can turn off autocommit, but now we have to be careful - a transaction will automatically be started when the first statement is executed (even if it is a SELECT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_conn.rollback()\n",
    "pg_conn.autocommit = False\n",
    "pg_execute(pg_conn, cheating_update_str)\n",
    "pg_conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>What really should be doing here is handling errors and rolling back the transaction if any of the statements fail - there is more detail on that in the <b>Cockroach-Bank-App</b> notebook</p>\n",
    "<p>Now let's execute a more complex SQL statement bringing back some aggregate data (min,max) and examine a subset of the result set using pretty print ...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_query_str = \"\"\"\n",
    "SELECT gender||':'||category as category, count(1) as number, \n",
    " min(total_time) AS min_time, max(total_time) AS max_time,  max(total_time)-min(total_time) AS range\n",
    "FROM results \n",
    "GROUP BY gender,category \n",
    "ORDER BY gender,category\n",
    "\"\"\"\n",
    "result = pg_fetch_all(pg_conn, category_query_str)\n",
    "pp.pprint(result[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can now process the data returned in <i>result</i> (which is an array of tuples) and show the output as HTML.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_str='<table><tr><th>Age Group</th><th>Number</th><th>Fastest</th><th>Slowest</th><th>Range</th></tr>'\n",
    "for category in result:\n",
    "    html_str += '<tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td></tr>'.format(category[0],category[1],category[2],\n",
    "                                                                                                    category[3],category[4])\n",
    "html_str += '</table>'\n",
    "display(HTML(html_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Some cool libraries to help us</h2>\n",
    "<p>Much as I enjoy generating raw HTML with Python, there are easier ways to do this. Let's use some libraries that make the job of selecting and displaying data much simpler ...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLAlchemy is an object relational mapping (ORM) library that can be used to interact with a database in an object-oriented way (see the Cockroach University Python Developer course for a fully worked example), but here we are simply using it to load data from the database into a Pandas dataframe</p>\n",
    "<p>We have implemented a CockroachDB dialect for SQLAlchemy for better compatibility so we need to tweak the URL to tell SQLAlchemy that it is dealing with Cockroach rather than PostgreSQL and then create an engine to retrieve data from CockroachDB</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sqlalchemy_url = my_cc_free_tier_url.replace('postgresql','cockroachdb')\n",
    "engine = create_engine(my_sqlalchemy_url)\n",
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_sql_query('select * from results order by position',con=engine)\n",
    "df_full.info()\n",
    "df_full.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Pandas and the SQLAlchemy engine have done all the hard work loading the data from the results table and displaying it in a much more readble format with minimal coding</p>\n",
    "<p>Let's run the same query we ran earlier using this setup ...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = pd.read_sql_query(category_query_str,con=engine)\n",
    "df_cat.info()\n",
    "df_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Visualising data</h2>\n",
    "<p>We can build on the work we have done so far and use matplotlib to visualise data extracted from CoackroachDB. In the example below we will select the rows from the results table in position order and plot a graph of the finish time in minutes against the finishing position.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using the inline backend\n",
    "%matplotlib inline \n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "print ('Matplotlib version: ', mpl.__version__) # >= 2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_query_str = \"\"\"\n",
    "SELECT position, (total_time::INT8)/60 as time_in_mins \n",
    "FROM results \n",
    "ORDER BY position\n",
    "\"\"\"\n",
    "df_pos = pd.read_sql_query(position_query_str,con=engine)\n",
    "finish_times = df_pos['time_in_mins']\n",
    "finish_times.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finish_times.plot(kind='line')\n",
    "\n",
    "plt.title('Thorpe Park Triathlon Finish Times')\n",
    "plt.ylabel('Time in minutes')\n",
    "plt.xlabel('Position')\n",
    "\n",
    "plt.yticks(np.arange(60, 180, 20))\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Close the connection</h2>\n",
    "<p>Let's be tidy and close the connection. After you execute the following cell you should see that the connection is no longer shown by the <code>show sessions</code> command in the CLI and the closed attribute is now set to 1 (True)<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_conn.close()\n",
    "pg_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.dispose()\n",
    "engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>That's it folks!!</h2><p>That's the end of this whistlestop tour of Python and CockroachDB - we hope you enjoyed it and found it informative - if you did, tell your friends and colleagues; if you have any suggestions for improvements and additional material then please let us know via the community Slack channel<p> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
